h1
  | ほぼ素のRailsアプリだった「スピカとチロル」が本番環境で安定動作するまで

section
  
  p
    span
      | ただ `rails new` しただけのアプリケーションである
    a[href="https://st.jyllsarta.net/"]
      | スピカとチロル
    span
      | のアルファ版公開 ~ 本番環境での安定動作が実現するまでにやったことをまとめてみました。

section
  h2
    | もくじ
  ul.with_point
    li
      | 前提とあらすじ
    li 
      | スピカとチロルの特徴
    li 
      | おおまかアーキテクチャ解説
    li 
      | このゲーム特有の処理
    li 
      | 本番リリース！からのタイムライン
    li 
      | 終わりに

section
  h2
    | 前提
  p 
    | スケーラブルで堅牢なシステムを完成させたキラキラした話ではなく、小規模でサイズも大きくないサーバを無駄なく使えるようにするまでの話になります。このお話を読んでもらいたい人はこんな方たちです
  ul.with_point
    li 
      | ハッカソンや個人制作で動くWebアプリケーションを作ったことがあるものの、それを本番で動くシステムとして動作させた経験のない人
    li 
      | スピカとチロルリリース初期に行っていたインフラ対応の裏側を知りたい人
    li 
      | Mackerel のメトリクスの読み方に興味がある人(今回とても助けられました)

section
  h2
    | おおまかアーキテクチャ解説
  p 
    | すごく単純に1台のEC2の中で全部受け切る前提にしておいて、受けきれなくなってからスケールも可能アーキテクチャです。
      ユーザの進捗データはキャッシュサーバ・DBのみに保存されているので、これらの参照先を切り替えればアプリケーションサーバの数を増やせる作りです。(結果的に それが必要になるほどの負荷は来ませんでしたが)
  p 
    | TODO: 図を作って挿入する

section
  h2
    | このゲームのインフラ的特徴
  p 
    | 
  ul.with_point
    li 
      | お金が絡まないので、求められるサービスレベルの水準は高くない。サーバが落ちたとして、ゲームの評判が落ちる以上のダメージはない
    li 
      | 完全趣味活動なので、サーバのリソースを可能な限り小さく保ちたい。AWSのサービスを広範囲で使うほどに予算を食うので、1台のEC2サーバに押し込みたくなる
    li 
      | 半放置ゲームなのでつけっぱなしにするプレイスタイルが多い。30秒に1回サーバに進捗を問い合わせるので、アクティブユーザの数に対してほぼ線形に負荷が上昇する
    li 
      | 身内向けのアルファ版を本番リリース3ヶ月前に本番とほぼ同様の構成で公開しており、その時はユーザ10人ほどを t3a.micro インスタンスで乗り切った。
        このときに Rails / DBのロジックには特段のボトルネックはなく、どのAPIも妥当な時間でレスポンスを返せていることを確認済み

section
  h2
    | 本番リリース！
  p 
    | TODO: 書く


- - -
以下流れメモ

5/8 リリース `t4g.small` で公開
https://twitter.com/jyll/status/1390971191779725313

けそりんブースト
https://twitter.com/jyll/status/1391736686892122112

けそブースト耐えた
https://twitter.com/jyll/status/1392036835753283585

リリース後1ヶ月は特段の問題なく耐え切った。累計プレイヤー数1000人、本編のクリア者は200人ほど

# 6/26 13:17 ブログで紹介されてアクセス急増。ロードアベレージ・CPU利用率のアラートで気づく
とりあえず本番環境に自分でもアクセスし、ゲームが動作していることを確認。
https://twitter.com/jyll/status/1408641171442655235

# 6/26 22:40 毎日行っているのログローテーションによる圧縮が来る前にディスクが埋まりかけてアラート
そもそもディスク容量が16GBとかなり小さめだったので、EBSを無停止で48GBまで拡張して対応
https://twitter.com/jyll/status/1408782199407538178

# 6/27 02:46 CPUクレジットを使い果たしたのに気づく
t系インスタンスだったので当然だったが、Mackerelでは見ていない領域+EBSの方を対応して満足してしまった。
このタイミングから目に見えてゲームの動作が遅くなり、体験が非常に悪くなる
今後のアクセスが読めないこともあり、安全をとって `c5.large` インスタンスに変更。
このタイミングで、累計プレイヤー数が2000人を突破。
https://twitter.com/jyll/status/1408844073935392768

# 6/27 10:00 インスタンスをスケールアップしたものの、まだ重い
https://twitter.com/jyll/status/1409148695480733697
昨晩インスタンスのスケールアップをしたにもかかわらず、ロードアベレージは数時間で昨晩の水準まで上昇してしまう。ブログのコメントでもまだ重いとの報告が続く。
Mackerelの指標を見る限りCPU利用率100%付近で上限に達しており、インスタンスの性能を使いきれていないように見える。
インスタンスにSSHで入り、top を確認するとCPU利用率100%で頑張っているrubyのプロセスを発見。1プロセスで捌き切れる限度まで達していたようです。

Rails標準の Puma の設定では、1プロセスで全てを捌き切るようになっていたようです。
c5.large の vCPU は 2なのでそれに合わせてpumaも2プロセスで動作させるようにしたところ、体感の遊び心地は大幅に改善して意図通りのゲーム体験が戻ってきました。

参考: 
https://qiita.com/snaka/items/029889198def72e84209
https://github.com/puma/puma/blob/master/docs/deployment.md

プロセス数を増やしたにもかかわらずCPU利用率がそこまで伸びきらなかったのは、Pumaの1プロセスでの並列性の方に限界が来ていて、CPUの方は少し余裕があったのだろうかと推測しております。

# 6/28 9:32 夜を乗り切った

ゲームの遊び心地が改善した状態で一晩の山を耐え切り、無事安定動作させることができました。
その後数日様子を見ておりましたがアラートが出ることはなく、無事ブログ経由の流入層みんなにゲームを遊んでもらうことに成功しました。
https://twitter.com/jyll/status/1409308803049218048

# いま

8000人弱のアカウントがあり、1500人にラスボスを倒してもらえました。予想以上の大繁盛です。作った甲斐がありました。
